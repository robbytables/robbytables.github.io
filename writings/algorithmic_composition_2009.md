

Algorithmic Composition:  
Methods of Non-Human Musical Creation  
Robby Grodin  
Northeastern University  
	Modern day technology has outfitted composers with an overabundance of sources with which to build their musical language. With this wealth of influences at their hands, composers often find it difficult to induce thinking outside of their normal patterns. New instruments and technologies come regularly to help     musicians think outside the box, but one method has stood the test of time based on a simple idea: remove your thought process entirely by automating the process. By relying on mathematical computation to produce musical means, a composer can develop not only single compositions but even new styles of composing they could never have dreamed of. There are patterns all around us, in nature, that we can manifest in compositions to better understand both the patterns and music. Not only can we find these patterns in nature, but in the music of composers long deceased. Computer-savvy composers can take this information and pump them into a computer to create a new Mozart symphony, with startling accuracy. Though the compositions are still general and will not be terribly interesting in the musical sense, the algorithms written are most important and have infinite uses in musical academia.  
	Algorithmic Composition is defined as “the process of using some formal process to make music with minimal human intervention” (Maurer, 2009). This includes mapping musical aesthetics to the outputs of mathematical functions, probability chains, random values within pre-defined ranges, etc. This form of composing wasn't invented, nor was it discovered. The most accurate description of the origins is to say that it was derived from over a thousand years of rule-based composition. This all began some time around the year 895 CE when Hucbald of St. Amande penned *Musica enchiriadis,* a work containing rules for developing canonical voices in Gregorian chants (Essl, 2008, 109). Organum, the process described, was not only the earliest record of algorithmic composition but also the most simplistic. Canonical voices were to be written in parallel fourths or fifths polyphony. These rules are very much like grammar based algorithmic composition, in that the next element is based deterministically on what came before.  
	For many years, scholars have attempted to manually write music in the styles of deceased composers. But what if Mozart had never died? One could only imagine a new counting system would have to be invented to catalogue his symphonies if he were still alive today. And if Bach were still here? What about Shakespeare, or Euclid even? Scholars of the great intellectuals are allowing their idols to continue creating, by allowing their own ideas to act as the manifestations of the deceased's own possible experiments. Much in the same way as a student would finish his mentor's requiem, we can deduce algorithms based on great composers' musical languages and imagine (as well as re-imagine) their works. When one compiles a computer algorithm written by someone else with the intention of producing a score, the resulting music is the product of the author of the algorithm, and they are the composer (Jacob, 1996).   
	This is just one use of algorithmic composition. More useful is the ability to step back from the composition process, in order to escape and effectively evade one's own musical language. There are detractors, however, who disagree with the methodology involved. They claim that algorithmic compositions do not sound 'good', in the traditional sense of the matter as it can create awkward results that a human would not consider (deterministically) a good 'fit' for the situation. Some say that the computer is too involved, as many programs involve high level coding languages. These arguments are bunk, as musical language is based on acculturation and preference. By not relying on one's ear for composing, the computer makes decisions that go against the composer's tendencies. This goes back to the argument made by composers who rely strongly on the ear.   
	At this point the argument becomes more about the definition of the term 'sounding good', which is highly controversial. Decisions made by a computer cannot check themselves if they sound pleasing to a human ear, but they are based on mathematical facts derived from music that does sound ‘good’. The difference is that a computer has only the musical language of the information fed to it. It doesn’t hear jingles on the radio, or an old lady humming to herself on a bench. Therefore the musical language is not gradually acquired as ours is, which has its own set of benefits and pitfalls.

HISTORY  
	As a computer is not required to create algorithmic compositions, this practice of creating music predates computational machinery. But the era of technology has expedited the process greatly, as well as improved our understanding of algorithms and possible ways to work with them. Franz Josef Haydn, as well as other 18th century composers, used dice to create aleatoric (otherwise known as chance) music. One of Haydn's dice games (musikaliches Wūrfelspiel) was comprised of two 6 x 8 matrices, the columns representing eight measures in a typical classical phrase, and the rows corresponding to different outcomes of throwing a single die (Cope, 1997, p. 197). This must have been a time consuming process, having only a dice in place of a computer. John Cage, in composing his *Music of Changes* in 1951, spent nine months flipping coins to determine every aspect of his piece (Muscutt, 2007, p. 11). If only he had a machine that could execute that process for him in nine seconds? The LISP command (random 2\) comes to mind, which produces a result of 0 or 1, a binary system not unlike flipping a coin.   
	About half a decade later, in 1957, Lejaren Hiller and Leonard Isaacson composed the ILLIAC suite for string quartet. It was not without assistance that they completed this task, as the ILLIACI mainframe computer at University of Illinois did a large portion of the work. Through experimenting with computer-executed algorithms, Hiller was able to not only create multiple pieces, but also four different mathematical models translated into computer algorithms which would produce four distinctly different forms of compositions (Essl, 2008, p. 112). Using probability distribution Hiller composed four movements: aleatoric counterpoint, strict counterpoint, rhythmic and dynamic experimentation, and twelve-tone serialism (Hiller, 1989, Track 5). The ILLIAC represented a new era in the future of computer-aided composition. Listeners can hear traditional musical patterns. Perfect counterpoint can be perceived in the second movement without any notion that a computer composed the piece. 

METHODOLOGY 

*Grammar-Modeled*  
	While the most complex algorithmic compositions require complex knowledge of math and computation to understand, Cope offers a very simple example of a twelve-tone composition to illustrate basic concepts. The composer begins by creating an array (X) of twelve different tones. The computer is then told to select one random tone from X and place that into variable Y. If X is now empty, the system restarts. If not, the X value used is removed, another is chosen and placed into Y (Cope, 1997, p. 193). The result is a list of values that can be mapped to any musical aesthetic the composer decides upon, ultimately producing a composition.   
	Algorithmic composition that is used to emulate the musical language of a composer is considered grammar-modeled composition. These systems are constructed by studying the musical language of a specific composer or school of composers. David Cope's EMI system (sometimes referred to as Emmy) does just that. By "studying" two or more compositions, Emmy can compose a piece in a similar style with startling accuracy (Muscutt, 2007, p. 13).   
	The EMI process has six core steps. First, the composer encodes at least two compositions and feeds them into the system (Cope's language of choice is LISP, though it is rather outdated at this point). The system then compiles a list of patterns found by cross-referencing the encoded works. As composers will use a theme only in a certain location of the piece, (such as introductions, cadences, etc.) this is noted and stored with the motifs in a library. Cope refers to this as superimposition. (4) A composition is produced based solely on the rules compiled in step two. (5) ATN (augmented transition network, which will be explained later) is applied, combining the "signatures" (themes) from step three with the rule-based composition from the previous step. (6) One of the most impressive steps, Emmy shapes the texture of the piece to not only conform to the composer's tendencies, but to ensure that heavily weighted themes do not lose their character (Cope, 1991, p. 152-3).  
	One interesting concept here is that the system can actually learn a composer's style by processing pieces. In a recent interview, Cope related a store about an Emmy composed Mazurka in the style of Chopin. The piece was being presented to pianists studying at the observatory in Moscow, and they were unimpressed, remarking that Chopin would never have composed that piece. He went on to explain that an influence of Chopin's, John Field, heard Chopin's music and said he was "unimpressed, and certainly would not have done this or that" (Muscutt, 2007, p. 12). While a composer’s musical language can be channeled through Emmy’s compositions, it does not have the ability to emulate the evolution of their compositional style. This would be, of course, impossible, as a computer cannot foresee a composer inventing a new genre, finding God, or meeting the Beatles.  

*Hierarchical Analysis*  
	The idea of computers learning musical styles based on encoded works is known as hierarchical Shenkerian analysis. Programs are written to perform this analysis and strip away all of the ornamentation of a composition to reveal what’s called the Ursatz of the piece. The Ursatz is the fundamental structure of the piece, often an overly simplified analysis such as a basic chord pattern or key changes (Cope, 1991, 37). A common way to execute this is with neural networks. A neural network is a way to create multiple inputs to a learning system. Multiple compositions are fed in, and after the analysis is run a composition is made. The composition is fed through the machine and checked against the provided pieces, and edited. The piece is passed around, edited, redone, etc. until an acceptable product is achieved. Many like this form of algorithmic establishment as it’s more akin to human thought processes than rule-based systems (Cope, 1997, p. 194).  
	In the same way that linguists are concerned with parsing sentences, practitioners of hierarchical algorithms parse musical phrases. Many composers specializing in grammar based algorithmic composition analyze pieces to construct a template for musical signatures. While there is a more intricate relationship between tones in a key than nouns and verbs in language, Cope offers up the following paradigm for the key of C major. The notes C F and G are the most important notes in the scale, though A can replace C as a tonic and D can replace G (Cope, 1991, p. 32). Already we can see that there is a certain weight given to each note in the scale, and by coding this we can produce musical phrases with introductions, elaborations, and cadences. Cope channeled these ideas into the SPEAC system in 1985 to better describe motion between tones (Cope, 1991, p.32).  
	Under SPEAC, a note is represented by one of the five letters that make up the acronym. S stands for statement, as in notes that have no relation to the rest of the material. P, the preparation, regards statements that are prefaced, and E (extension) is used to describe statements that are lengthened. Antecedents (A) have a necessary relationship with consequents (C), same as in typical music theory. By writing out different permutations of identifiers (i.e. S A P C, or A, E, C etc.) and associating notes, chords, or groups of these with the identifiers Cope was able to create musical phrases much in the same way we construct sentences every day (Cope, 1991, p.35). This is similar to the first two steps of the EMI system, in which the computer learns patterns based on encoded pieces. Another application of this idea is developing musical syntax. By creating a sentence structure and gradually replacing parts of the sentence with actual words, at first arbitrarily. Deterministic relationships drive the replacement for the rest of the elements, until a sentence that is coherent (albeit possibly awkward) is formed (Cope, 1991, p. 52).  
	It's not difficult to imagine using this system in regards to music. By replacing nouns with tonics, and verbs with dominants and so on, we can create an actual language out of music that can be put together algorithmically. To implement this concept in Emmy, Cope utilized ATN functions. ATN stands for Augmented Transition Networks. These systems, popularized by Harvard professor William Woods, are used recursively to connect sentence elements via various prescribed actions (i.e. "Seek Noun", "Seek Verb", "Jump", etc.) (Cope, 1991, p. 52).   

*Self-Similar Functions*  
	Stephen Hawking presented a concept called "turtles all the way", which is rather popular amongst computer scientists as a humorous view of recursion. Recursive functions repeat themselves until they reach a termination clause, such as the end of a list, or a predetermined state. These functions must end somewhere in order to work, except for a few cases. One of these is the idea of fractals. Fractals are recursive in nature, and repeat themselves at continuously larger/smaller levels based on the relationship x(k+1) \= λ x k (1 \- x k)  (Cope, 1997, p. 197). Looking at the coast of California from the International Space Station, for example, is similar to the shape of the coast from a plane, or a building, or a boat even.  
	Gary Lee Nelson is perhaps the most widely recognized composer of fractal music. His piece *Fractal Mountains* (1988-89) is based on the idea of computer graphics. When creating a graphic of a tree, or a coastline, or a mountain (all of which are fractal in nature) the designer uses fractal recursion to create the ever-shortening lines. He began composing the piece by drawing out the general shape of a mountain range. Each vertex represented a note's attack. Multiple fractal functions are in use to represent the vast number of musical attributes covered (time, pitch, spacialization, etc.) (Nelson, 2009, p. 3).  
	Another form of recursive replacement algorithms is the L-system. Named after the biologist Aristid Lindenmeyer, L-systems were originally used to model the growth processes of plants. Based on a self-similar recursive form, L-systems begin with a set of axioms and evolve infinitely into simple derivatives. Take, for example, the axiom set containing (a=b, b=ab). Beginning with the axiom a, our first derivative is b, then ab, bab, abbab, bababbab, etc (Supper, 2001, p. 50). All it takes from here is to map these axioms to musical phrases or even aesthetics to form a composition.  Hanspeter Kyburz did exactly this in 1993 when composing Cells, for saxophone. By basing his axioms on numeric values, and creating rules based on the values of the derivatives, Kyburz organized cells (similar to minimalist music) based on 13 derivatives of his algorithm (Supper, 2001, p. 51). As these algorithms spool on forever in self-similar patterns they could be considered fractals, which are very commonly used as the basis for algorithmic compositions.  
	The idea of self-replicating melodic themes goes beyond the ideas of basic fractal imaging. Tom Johnson wrote about the ideas of mathematical sequences that are infinite in length, and therefore can be mapped to musical parameters to create music. In his piece *Narayana's Cows*, Johnson used the Narayana sequence to represent rhythm and pitch (Johnson, 2001). Another example would be to derive pitch and rhythm from a quadratic sequence and the first set of differences derived from the numbers.   
	Johnson also found patterns based on Pascal's triangle, also based on quadratic equations and the binomial theorem. One of the most striking patterns he found was based on the possible 8178 chords on his piano. Based on the properties of the individual chords (mainly the number of notes contained) Johnson mapped the chords to Pascal’s triangle to order them in piece *The Chord Catalogue*, one of the only compositions that utilizes all chords possible on the keyboard.   
	Self-replicating melodies came into play in his piece *Rational Melody No. 15* in the form of melodic canon. A melody was composed such that if a performer were to play every other note, it would be the same as if they had played every note. This presents the notion of ratios of replication, in this case a ratio of 2:1. He executed this again in *Loops for Orchestra* using modulo math. Using only the notes D E G F and rests, Johnson assigned each a set of unique numbers from zero to twenty-one. Using rests allowed for smaller melodies to fill in gaps, and the result is a series of rhythmic and melodic canons resting every seven 16th notes (Johnson, 2001). The use of modulo math in this respect is reminiscent of Messiaen’s obsession with isorhytmic composition in his *Quatour pour la Fin du Temps*.

*Stochastic*  
 	Stochastic composition was conceived by Iannis Xenakis in the mid-to-late 1950's. Trevor Wishart defines it as: Stochastic music is based on a process in which the probabilities of proceeding from one state, or set of states, is \[sic\] defined. The temporal evolution of the process is therefore governed by a kind of weighted randomness, which can be chosen to give anything from an entirely determined outcome, to an entirely unpredictable one (Wishart, 1994). James Tenney's piece *Dialogue* (1963) is a very creative algorithmically generated stochastic piece based on relationships between two different timbres. The piece sounds like a musical conversation between noise-bands and pure tones. While it is not the most exciting piece, the methodology behind the construction is rather interesting.  
	In composing the algorithms for *Dialogue*, Tenney mapped out starting and ending values for each musical attribute in every ‘statement’. Based on his algorithms, the computer then interpolated values for the clangs in between. Parameters automated include note duration, amplitude, AM rate, timbre (in reference to discrete waveforms), amplitude envelope, vertical density, and the probability of a rest. For wavetable references, such as timbre and envelopes, the parameters morphed gradually between settings instead of changing abruptly (Polansky,). This paradigm of setting loose rules and allowing for randomization within boundaries is a great example of stochastic music as Xenakis had envisioned.

CONCLUSION  
	Algorithmic composition is still a developing field. It never receives the fanfare many feel it deserves due to the controversy involved, as well as the lack of interest in the musical results. The rapidity of progress in this field is limited as well due to technological constraints. New boundaries are being broken every day in the field of computation as more efficient algorithms are produced. Newer genres have yet to be touched by the scope of algorithmic composition. Perhaps we will be able to electronically produce plunderphonic pieces soon, or even mixed works. The possibilities of algorithmic composition are limited not to musical constraints, but those in the fields of mathematics and technology. While it is possible that one day we will be able to build a computer that will compose music no human before it could ever have, that step is far ahead and many crucial tasks are in the more immediate future.   
WORKS CITED  
Cope, D. (1991). *Computers and musical style (computer music and digital audio series).* 	Winnipeg: A-R Editions.

Cope, D. (1997). *Techniques of the contemporary composer.* Reston: Schirmer.

Essl, K. (2008). Algorithmic composition. *The Cambridge Companion to Electronic 			Music (Cambridge Companions to Music)* (pp. 107-125). New York: Cambridge 			University Press.

Hiller, L. (1989). String quartets no. 4\. On *Computer music retrospective* \[CD\]. Mainz, 			Germany: Wergo.

Jacob, Bruce L. "Algorithmic Composition as a Model of Creativity." *Organised Sound* 	1.3 (1996). University of Michigan, 1996\. Web. 14 Nov. 2009\. 	\<http://www.ece.umd.edu/\~blj/algorithmic\_composition/algorithmicmodel.html\>.

Maurer, John A. "The History of Algorithmic Composition." *CCRMA | Center for			Computer Research in Music and Acoustics*. Stanford University. Web. 17 	Nov. 2009\. \<https://ccrma-www.stanford.edu/\~blackrse/algorithm.html\>.

Muscutt, K. (2007). Composing with algorithms: an interview with David Cope. 			*Computer Music Journal*, *31*(3), 10-22.

Nelson, G. L. (n.d.). Gary Lee Nelson. *TIMARA=technology in music and related arts*. 		Retrieved December 5, 2009, from 	http://timara.con.oberlin.edu/\~gnelson/gnelson.htm

Supper, Martin. "A few remarks on algorithmic composition." *Computer Music Journal* 	25.1 (2001): 	48-53. Print.

Wishart, T. 1994\. Audible Design. York, England: Orpheus the Pantomime.

